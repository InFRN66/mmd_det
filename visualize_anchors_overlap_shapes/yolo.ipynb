{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from vision.yolo.darknet53 import DarkNet53, Conv_Bn_Leaky, DarkNetBlock\n",
    "from vision.yolo.yolov3 import create_net\n",
    "\n",
    "\n",
    "from vision.yolo.yolo_config import Config\n",
    "cfg = Config()\n",
    "\n",
    "import torch\n",
    "img = torch.ones(1,3,416,416)\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "from torch.utils import data\n",
    "from vision.yolo.yolov3 import MultiboxLoss\n",
    "from vision.yolo.voc_dataset import detection_collate, VOCDetection\n",
    "train_dataset = VOCDetection(\"../../YOLOv3_Pytorch/data/datasets/VOCdevkit0712\", [('0712', '0712_trainval')], (416, 416), 3, True, \"VOC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det torch.Size([3, 507, 85]) 13 32 507\n",
      "det torch.Size([3, 2028, 85]) 26 16 2028\n",
      "det torch.Size([3, 8112, 85]) 52 8 8112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yhosoya/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_iterator = iter(data.DataLoader(train_dataset, \n",
    "                                      3,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=4,\n",
    "                                      collate_fn=detection_collate))\n",
    "\n",
    "net = create_net(cfg, is_test=False)\n",
    "net.cuda()\n",
    "img, target = next(batch_iterator)\n",
    "img = img.cuda()\n",
    "\n",
    "out = net(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_sigmoid, add_sigmoid_offsef = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mloss = MultiboxLoss(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:fore_mask_t tensor([[112, 164,  36,  ..., 109, 127,   0],\n",
      "        [  0,  43,  19,  ...,   0,   0,   0],\n",
      "        [  0,   0,   0,  ...,   0,   0,   0]], device='cuda:0',\n",
      "       dtype=torch.uint8)\n",
      "cuda False False\n",
      "cuda False False\n",
      "cuda False False\n",
      "2:fore_mask_t tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0', dtype=torch.uint8)\n",
      "xy_loss 1.8345 wh_loss 0.99297 cls_loss 75.12937 ave_cls 0.47188 Obj 0.42312 no_obj 0.50793 fore_conf_loss 3.5771 back_conf_loss 22802.49609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../vision/yolo/yolov3.py:337: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  cls_fore_mask_t = fore_mask_t.new_tensor(fore_mask_t).view(batch_size, num_pred, 1).expand_as(cls_pred)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(7678.0962, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mloss(add_sigmoid, add_sigmoid_offsef, target, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../YOLOv3_Pytorch/weights_trained/convert_darknet53.pth\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = torch.load(\"../../YOLOv3_Pytorch/weights_trained/convert_darknet53.pth\")\n",
    "# for i in weight.keys():\n",
    "#     print(weight[i].shape)\n",
    "len(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../../YOLOv3_Pytorch/eval/aeroplane_pr.pkl\", \"rb\") as f:\n",
    "    out = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58.395, 57.12 , 57.375])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array([0.229, 0.224, 0.225])*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo.py, images/dog.jpg\n",
    "\n",
    "torch.Size([1, 10647, 25])\n",
    "tensor([[1.7449e+01, 1.9058e+01, 9.4442e+01, 7.6652e+01, 1.1803e-07],\n",
    "        [1.3544e+01, 1.7641e+01, 1.4986e+02, 1.8285e+02, 1.1748e-07],\n",
    "        [1.4749e+01, 1.6207e+01, 3.6843e+02, 3.4552e+02, 3.6790e-07]],\n",
    "       device='cuda:0')\n",
    "\n",
    "# fragment.py, images/dog.jpg\n",
    "torch.Size([1, 10647, 25])\n",
    "tensor([[1.7449e+01, 1.9058e+01, 9.4442e+01, 7.6652e+01, 1.1803e-07],\n",
    "        [1.3544e+01, 1.7641e+01, 1.4986e+02, 1.8285e+02, 1.1748e-07],\n",
    "        [1.4749e+01, 1.6207e+01, 3.6843e+02, 3.4552e+02, 3.6790e-07]],\n",
    "       device='cuda:0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo\n",
    "detection_postprecess_fragment\n",
    "[[110.464676   127.27025    555.2255     453.0021       0.99978393    0.99984264   1.        ]\n",
    " [474.4371      84.49383    672.11847    167.49568      0.99996555    0.99989295   6.        ]\n",
    " [123.11983    215.24858    306.22607    551.7865       0.99237096    0.97638875  11.        ]]\n",
    "\n",
    "\n",
    "# fragment\n",
    "detection_postprecess_fragment\n",
    "tensor([[0.9999, 0.2108, 0.2366, 0.7306, 0.7669],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([121.4208, 181.7088, 420.8256, 588.9792])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal\n",
    "torch.Size([10647, 7])\n",
    "tensor([0., 0., 0., 0., 0.], device='cuda:0')\n",
    "tensor([ 1.,  6., 11.], device='cuda:0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluating detections\n",
    "Writing aeroplane VOC results file\n",
    "Writing bicycle VOC results file\n",
    "Writing bird VOC results file\n",
    "Writing boat VOC results file\n",
    "Writing bottle VOC results file\n",
    "Writing bus VOC results file\n",
    "Writing car VOC results file\n",
    "Writing cat VOC results file\n",
    "Writing chair VOC results file\n",
    "Writing cow VOC results file\n",
    "Writing diningtable VOC results file\n",
    "Writing dog VOC results file\n",
    "Writing horse VOC results file\n",
    "Writing motorbike VOC results file\n",
    "Writing person VOC results file\n",
    "Writing pottedplant VOC results file\n",
    "Writing sheep VOC results file\n",
    "Writing sofa VOC results file\n",
    "Writing train VOC results file\n",
    "Writing tvmonitor VOC results file\n",
    "VOC07 metric? Yes\n",
    "AP for aeroplane = 0.7992\n",
    "AP for bicycle = 0.7962\n",
    "AP for bird = 0.6904\n",
    "AP for boat = 0.6530\n",
    "AP for bottle = 0.6464\n",
    "AP for bus = 0.7973\n",
    "AP for car = 0.8650\n",
    "AP for cat = 0.7864\n",
    "AP for chair = 0.5724\n",
    "AP for cow = 0.7435\n",
    "AP for diningtable = 0.7032\n",
    "AP for dog = 0.7429\n",
    "AP for horse = 0.7940\n",
    "AP for motorbike = 0.7937\n",
    "AP for person = 0.7833\n",
    "AP for pottedplant = 0.5206\n",
    "AP for sheep = 0.7038\n",
    "AP for sofa = 0.7023\n",
    "AP for train = 0.7921\n",
    "AP for tvmonitor = 0.7499\n",
    "Mean AP = 0.7318\n",
    "~~~~~~~~\n",
    "Results:\n",
    "0.799\n",
    "0.796\n",
    "0.690\n",
    "0.653\n",
    "0.646\n",
    "0.797\n",
    "0.865\n",
    "0.786\n",
    "0.572\n",
    "0.743\n",
    "0.703\n",
    "0.743\n",
    "0.794\n",
    "0.794\n",
    "0.783\n",
    "0.521\n",
    "0.704\n",
    "0.702\n",
    "0.792\n",
    "0.750\n",
    "0.732\n",
    "~~~~~~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(11, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
